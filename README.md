# Yolo_RaspberryPi
Проект реализующий портирование нейронной сети на полётный контроллер БПЛА построенный на базе RaspberryPi

## Оглавление
- [Описание проекта](#описание-проекта)
- [Требования](#требования)
- [Установка](#установка)
- [Использование](#использование)
- [Структура проекта](#структура-проекта)
- [Результаты проекта](#результаты-проекта)
- [Вклад](#вклад)
- [Лицензия](#лицензия)
- [Контакты](#контакты)

## Описание проекта
Этот проект посвящен портированию нейронной сети YOLOv8 на полётный контроллер беспилотного летательного аппарата (БПЛА) на базе Raspberry Pi CM4. Основная цель проекта - создать систему распознавания объектов в реальном времени, которая может быть использована для различных приложений, включая навигацию, обнаружение препятствий и мониторинг.

## Требования
Для успешного выполнения этого проекта необходимы следующие компоненты и библиотеки:

### Оборудование
- Raspberry Pi CM4
- Камера, совместимая с Raspberry Pi
- Платформа для БПЛА

### Программное обеспечение
- Raspberry Pi OS
- Python 3.7+
- OpenCV
- PyTorch
- YOLOv8

### Обновление пакетов
Обновите все пакеты Linux:
```sh
sudo apt update
sudo apt upgrade
```

## Установка
Следуйте инструкциям ниже для установки и настройки проекта:
### 1. Смонтируйте папку и перейдите в неё:
```sh
mkdir person_detect
cd person_detect
```
### 2. Установите виртуальную среду и активируйте её:
```sh
python3 -m venv env
source ./env/bin/activate
```
### 3. Скачать ultralytics:
```sh
pip3 install ultralytics
```
### 4. Конвертируем модель в формат NCNN:
```sh
yolo predict model='./yolov8n_ncnn_model' source='https://ultralytics.com/images/bus.jpg'
```
### 5. Запускаем тест использующий стандартную модель:
```sh
yolo export model=yolov8n.pt format=ncnn
```
### 6. Запускаем тест использующий модель в формате NCNN:
```sh
yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'
```
### 7. Настройте внешних модулей:
- Подключите камеру к Raspberry Pi CM4;
- Настройте камеру и убедитесь, что она работает корректно.

## Использование
Следуйте этим шагам для запуска нейронной сети на полётном контроллере:
### 1. Запустите скрипт распознавания объектов:
```sh
python3 test_camera.py
```
### 2. Просмотрите результаты:
Результаты распознавания объектов будут отображаться в режиме реального времени на экране

### Структура проекта
Описание структуры файлов и папок в проекте:
```bash
├── bus.jpg                     # Изображение для тестирования 
├── env                         # Каталог виртуального окружения Python
│   ├── bin                     # Исполняемые файлы и скрипты окружения
│   ├── include                 # Заголовочные файлы C/C++ для окружения
│   ├── lib                     # Библиотеки Python для окружения
│   ├── lib64 -> lib            # Символическая ссылка на каталог lib
│   ├── pyvenv.cfg              # Конфигурационный файл виртуального окружения
│   └── share                   # Общие файлы данных для окружения
├── runs                        # Каталог для хранения результатов запуска
│   └── detect                  # Подкаталог для хранения результатов детектирования
├── test_2.mp4                  # Видео файл для тестирования
├── test_camera.py              # Скрипт для тестирования работы с камерой
├── test_video.py               # Скрипт для тестирования работы с видео
├── yolov8n_ncnn_model          # Каталог с моделью YOLOv8n для NCNN (инференс движок)
│   ├── metadata.yaml           # Метаданные модели в формате YAML
│   ├── model.ncnn.bin          # Бинарные данные модели для NCNN
│   ├── model.ncnn.param        # Параметры модели для NCNN
│   └── model_ncnn.py           # Скрипт для работы с моделью NCNN
├── yolov8n.pt                  # Модель YOLOv8n в формате PyTorch
└── yolov8n.torchscript         # Модель YOLOv8n в формате TorchScript (для более эффективного выполнения)

```
## Результаты проекта

<p align="center">
  <img src="https://github.com/alexander-soko1ov/Yolo_RaspberryPi/blob/main/yolov8n.png" alt="Скорость обработки одного кадра используя стандарную модель YOLOv8n" />
  <br>
  <em>Скорость обработки одного кадра используя стандарную модель YOLOv8n</em>
</p>

<p align="center">
  <img src="https://github.com/alexander-soko1ov/Yolo_RaspberryPi/blob/main/yolov8n_ncnn.png" alt="Скорость обработки одного кадра используя модель YOLOv8n NCNN" />
  <br>
  <em>Скорость обработки одного кадра используя модель YOLOv8n NCNN</em>
</p>


## Вклад
Если вы хотите внести вклад в проект, пожалуйста, следуйте этим инструкциям:
1. Форкните репозиторий;
2. Создайте новую ветку (git checkout -b feature/имя_фичи);
3. Внесите свои изменения и закоммитьте их (git commit -m 'Добавил новую фичу');
4. Запушьте изменения в свою ветку (git push origin feature/имя_фичи);
5. Создайте Pull Request.

## Лицензия
Этот проект лицензирован под лицензией MIT. Подробности смотрите в файле LICENSE.

## Контакты
Для вопросов и предложений обращайтесь:
- Автор: Соколов Александр, Кузьмин Захар
- Email: 
- GitHub: 
